{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Q9wEuRdwY_E"
      },
      "source": [
        "**Quick-start:** If you just want to train a basic custom model for openWakeWord!\n",
        "\n",
        "Follow the instructions for Step 1 below. Each time you change the wake word, click the play icon to the left of the title to generate a sample and make sure it sounds correct. The first time it takes ~30 seconds but subsequent runs will be quick.\n",
        "\n",
        "Once you're satisfied with the pronounciation, go to the \"Runtime\" dropdown menu in the upper left of the page, and select \"run all\". Keep the tab open but feel free to do something else. After ~1 hour, your custom model will be ready and will automatically be downloaded to your computer!\n",
        "\n",
        "If you are a Home Assistant user with the openWakeWord add-on, follow the instructions [here](https://github.com/home-assistant/addons/blob/master/openwakeword/DOCS.md#custom-wake-word-models) to install and enable your custom model.\n",
        "\n",
        "---\n",
        "\n",
        "If you are interested in learning more about the custom model training process (and increasing the accuracy of your custom models), read through each step in this notebook and try experimenting with different training parameters. If you have any questions or problems, feel free to start a discussion at the openWakeWord [repo](https://github.com/dscripka/openWakeWord/discussions)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vl_FIEj-auGq"
      },
      "source": [
        "## Training your own openWakeWord models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "1cbqBebHXjFD",
        "outputId": "05ee74bd-cbe6-4e87-989f-a8a975bea4c3"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'generate_samples' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[2], line 47\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtext_to_speech\u001b[39m(text):\n\u001b[0;32m     39\u001b[0m     generate_samples(text \u001b[38;5;241m=\u001b[39m text,\n\u001b[0;32m     40\u001b[0m                 max_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m     41\u001b[0m                 length_scales\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m1.1\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     44\u001b[0m                 file_names\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_generation.wav\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     45\u001b[0m                 )\n\u001b[1;32m---> 47\u001b[0m \u001b[43mtext_to_speech\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget_word\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     48\u001b[0m Audio(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_generation.wav\u001b[39m\u001b[38;5;124m\"\u001b[39m, autoplay\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
            "Cell \u001b[1;32mIn[2], line 39\u001b[0m, in \u001b[0;36mtext_to_speech\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtext_to_speech\u001b[39m(text):\n\u001b[1;32m---> 39\u001b[0m     \u001b[43mgenerate_samples\u001b[49m(text \u001b[38;5;241m=\u001b[39m text,\n\u001b[0;32m     40\u001b[0m                 max_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m     41\u001b[0m                 length_scales\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m1.1\u001b[39m],\n\u001b[0;32m     42\u001b[0m                 noise_scales\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0.7\u001b[39m], noise_scale_ws \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0.7\u001b[39m],\n\u001b[0;32m     43\u001b[0m                 output_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./\u001b[39m\u001b[38;5;124m'\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, auto_reduce_batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     44\u001b[0m                 file_names\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_generation.wav\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     45\u001b[0m                 )\n",
            "\u001b[1;31mNameError\u001b[0m: name 'generate_samples' is not defined"
          ]
        }
      ],
      "source": [
        "# @title  { display-mode: \"form\" }\n",
        "# @markdown # 1. Test Example Training Clip Generation\n",
        "# @markdown Since openWakeWord models are trained on synthetic examples of your\n",
        "# @markdown target wake word, it's a good idea to make sure that the examples\n",
        "# @markdown sound correct. Type in your target wake word below, and run the\n",
        "# @markdown cell to listen to it.\n",
        "# @markdown\n",
        "# @markdown Here are some tips that can help get the wake word to sound right:\n",
        "\n",
        "# @markdown - If your wake word isn't being pronounced in the way\n",
        "# @markdown you want, try spelling out the sounds phonetically with underscores\n",
        "# @markdown separating each part.\n",
        "# @markdown For example: \"hey siri\" --> \"hey_seer_e\".\n",
        "\n",
        "# @markdown - Spell out numbers (\"2\" --> \"two\")\n",
        "\n",
        "# @markdown - Avoid all punctuation except for \"?\" and \"!\", and remove unicode characters\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import yaml\n",
        "from IPython.display import Audio\n",
        "if not os.path.exists(\"./piper-sample-generator\"):\n",
        "    !git clone https://github.com/rhasspy/piper-sample-generator\n",
        "    !wget -O piper-sample-generator/models/en_US-libritts_r-medium.pt 'https://github.com/rhasspy/piper-sample-generator/releases/download/v2.0.0/en_US-libritts_r-medium.pt'\n",
        "\n",
        "    # Install system dependencies\n",
        "    !pip install piper-phonemize\n",
        "    !pip install webrtcvad\n",
        "\n",
        "    if \"piper-sample-generator/\" not in sys.path:\n",
        "        sys.path.append(\"piper-sample-generator/\")\n",
        "\n",
        "    from generate_samples import generate_samples\n",
        "\n",
        "target_word = \"Hey Sen_she_ent\" # @param {type:\"string\"}\n",
        "\n",
        "def text_to_speech(text):\n",
        "    generate_samples(text = text,\n",
        "                max_samples=1,\n",
        "                length_scales=[1.1],\n",
        "                noise_scales=[0.7], noise_scale_ws = [0.7],\n",
        "                output_dir = './', batch_size=1, auto_reduce_batch_size=True,\n",
        "                file_names=[\"test_generation.wav\"]\n",
        "                )\n",
        "\n",
        "text_to_speech(target_word)\n",
        "Audio(\"test_generation.wav\", autoplay=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "9e7b5702f4f34efa91ed2b2b3fabd62b",
            "53c4e8d743204d36b80a267957f20e2b",
            "cffebad06704453a827883d23af371e2",
            "46348ce816ce40979a14d7a1f6e760da",
            "6b26acf8628f43749cbff0f41298a860",
            "69fadcb11a9840cba289e79c4dc449e2",
            "3b0e8a6138f7458e846fb1a2b5c39eac",
            "9f96400f76ae44219d1c3f5c9104e6e6",
            "30cd5019f5cc4affb551ef4d859ac13e",
            "89b2f53e578f40438cfd2cb5773bd4dd",
            "c23258cebd674fdcb1bbf13dfb1b9ed2",
            "28b901e22b93410b8e7a2358d1cd8005",
            "f4b2e3ca0c5b46dd9e7c704e543a5f45",
            "46caee6dc8954c55820c35d059f144b6",
            "798050445e6e4b688753137c835881c5",
            "864c43b961fe411d824fb32eb25a37b3",
            "a68023d84ab34248a312b2fa5a2892fd",
            "97ab69917e9f40b09dd2fa703a3765f8",
            "0106fa30d61a43d1baa5e23b2c2da35a",
            "c0514b32c9304b0fab7f89fdaa5d13b6",
            "d41b3c7af4e5466d8da393d637a058ee",
            "8281106d178d48a7ad614cab6a6fe537"
          ]
        },
        "id": "oWahyFO20_mh",
        "outputId": "59a49df7-3d90-4947-c31a-f42dbe9d59eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'openwakeword'...\n",
            "remote: Enumerating objects: 1186, done.\u001b[K\n",
            "remote: Counting objects: 100% (533/533), done.\u001b[K\n",
            "remote: Compressing objects: 100% (116/116), done.\u001b[K\n",
            "remote: Total 1186 (delta 438), reused 417 (delta 417), pack-reused 653 (from 1)\u001b[K\n",
            "Receiving objects: 100% (1186/1186), 3.21 MiB | 6.90 MiB/s, done.\n",
            "Resolving deltas: 100% (730/730), done.\n",
            "Obtaining file:///content/openwakeword\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting onnxruntime<2,>=1.10.0 (from openwakeword==0.6.0)\n",
            "  Downloading onnxruntime-1.20.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Collecting tflite-runtime<3,>=2.8.0 (from openwakeword==0.6.0)\n",
            "  Downloading tflite_runtime-2.14.0-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.0 in /usr/local/lib/python3.11/dist-packages (from openwakeword==0.6.0) (4.67.1)\n",
            "Requirement already satisfied: scipy<2,>=1.3 in /usr/local/lib/python3.11/dist-packages (from openwakeword==0.6.0) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn<2,>=1 in /usr/local/lib/python3.11/dist-packages (from openwakeword==0.6.0) (1.6.1)\n",
            "Requirement already satisfied: requests<3,>=2.0 in /usr/local/lib/python3.11/dist-packages (from openwakeword==0.6.0) (2.32.3)\n",
            "Collecting coloredlogs (from onnxruntime<2,>=1.10.0->openwakeword==0.6.0)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime<2,>=1.10.0->openwakeword==0.6.0) (25.1.24)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.11/dist-packages (from onnxruntime<2,>=1.10.0->openwakeword==0.6.0) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from onnxruntime<2,>=1.10.0->openwakeword==0.6.0) (24.2)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime<2,>=1.10.0->openwakeword==0.6.0) (4.25.6)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime<2,>=1.10.0->openwakeword==0.6.0) (1.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0->openwakeword==0.6.0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0->openwakeword==0.6.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0->openwakeword==0.6.0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0->openwakeword==0.6.0) (2025.1.31)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2,>=1->openwakeword==0.6.0) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2,>=1->openwakeword==0.6.0) (3.5.0)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime<2,>=1.10.0->openwakeword==0.6.0)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime<2,>=1.10.0->openwakeword==0.6.0) (1.3.0)\n",
            "Downloading onnxruntime-1.20.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (13.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m85.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tflite_runtime-2.14.0-cp311-cp311-manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m56.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: openwakeword\n",
            "  Building editable for openwakeword (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openwakeword: filename=openwakeword-0.6.0-0.editable-py3-none-any.whl size=17464 sha256=d937ddf926ed583ea67cf52fdc45802374088a7eb06df239c425d9a13ab98872\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-x6ceyohe/wheels/0c/57/fb/ff0f65816c3a56a203bf97b5fba7bcc37a99e64ac8862bf609\n",
            "Successfully built openwakeword\n",
            "Installing collected packages: tflite-runtime, humanfriendly, coloredlogs, onnxruntime, openwakeword\n",
            "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnxruntime-1.20.1 openwakeword-0.6.0 tflite-runtime-2.14.0\n",
            "Collecting mutagen==1.47.0\n",
            "  Downloading mutagen-1.47.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Downloading mutagen-1.47.0-py3-none-any.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.4/194.4 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: mutagen\n",
            "Successfully installed mutagen-1.47.0\n",
            "Collecting torchinfo==1.8.0\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
            "Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.8.0\n",
            "Collecting torchmetrics==1.2.0\n",
            "  Downloading torchmetrics-1.2.0-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics==1.2.0) (1.26.4)\n",
            "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from torchmetrics==1.2.0) (2.5.1+cu124)\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics==1.2.0)\n",
            "  Downloading lightning_utilities-0.12.0-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: packaging>=17.1 in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.8.0->torchmetrics==1.2.0) (24.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.8.0->torchmetrics==1.2.0) (75.1.0)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.8.0->torchmetrics==1.2.0) (4.12.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->torchmetrics==1.2.0) (3.17.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->torchmetrics==1.2.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->torchmetrics==1.2.0) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->torchmetrics==1.2.0) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.8.1->torchmetrics==1.2.0)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.8.1->torchmetrics==1.2.0)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.8.1->torchmetrics==1.2.0)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.8.1->torchmetrics==1.2.0)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.8.1->torchmetrics==1.2.0)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.8.1->torchmetrics==1.2.0)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.8.1->torchmetrics==1.2.0)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.8.1->torchmetrics==1.2.0)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.8.1->torchmetrics==1.2.0)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->torchmetrics==1.2.0) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->torchmetrics==1.2.0) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.8.1->torchmetrics==1.2.0)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->torchmetrics==1.2.0) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->torchmetrics==1.2.0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.1->torchmetrics==1.2.0) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.1->torchmetrics==1.2.0) (3.0.2)\n",
            "Downloading torchmetrics-1.2.0-py3-none-any.whl (805 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m805.2/805.2 kB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.12.0-py3-none-any.whl (28 kB)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m82.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m65.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m43.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m67.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, lightning-utilities, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torchmetrics\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed lightning-utilities-0.12.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 torchmetrics-1.2.0\n",
            "Collecting speechbrain==0.5.14\n",
            "  Downloading speechbrain-0.5.14-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting hyperpyyaml (from speechbrain==0.5.14)\n",
            "  Downloading HyperPyYAML-1.2.2-py3-none-any.whl.metadata (7.6 kB)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from speechbrain==0.5.14) (1.4.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from speechbrain==0.5.14) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from speechbrain==0.5.14) (24.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from speechbrain==0.5.14) (1.13.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from speechbrain==0.5.14) (0.2.0)\n",
            "Requirement already satisfied: torch>=1.9 in /usr/local/lib/python3.11/dist-packages (from speechbrain==0.5.14) (2.5.1+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (from speechbrain==0.5.14) (2.5.1+cu124)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from speechbrain==0.5.14) (4.67.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.11/dist-packages (from speechbrain==0.5.14) (0.28.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain==0.5.14) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain==0.5.14) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain==0.5.14) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain==0.5.14) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain==0.5.14) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain==0.5.14) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain==0.5.14) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain==0.5.14) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain==0.5.14) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain==0.5.14) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain==0.5.14) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain==0.5.14) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain==0.5.14) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain==0.5.14) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain==0.5.14) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain==0.5.14) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain==0.5.14) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain==0.5.14) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain==0.5.14) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.9->speechbrain==0.5.14) (1.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->speechbrain==0.5.14) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->speechbrain==0.5.14) (2.32.3)\n",
            "Collecting ruamel.yaml>=0.17.28 (from hyperpyyaml->speechbrain==0.5.14)\n",
            "  Downloading ruamel.yaml-0.18.10-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting ruamel.yaml.clib>=0.2.7 (from ruamel.yaml>=0.17.28->hyperpyyaml->speechbrain==0.5.14)\n",
            "  Downloading ruamel.yaml.clib-0.2.12-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.9->speechbrain==0.5.14) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->speechbrain==0.5.14) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->speechbrain==0.5.14) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->speechbrain==0.5.14) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->speechbrain==0.5.14) (2025.1.31)\n",
            "Downloading speechbrain-0.5.14-py3-none-any.whl (519 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.0/519.0 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading HyperPyYAML-1.2.2-py3-none-any.whl (16 kB)\n",
            "Downloading ruamel.yaml-0.18.10-py3-none-any.whl (117 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.7/117.7 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ruamel.yaml.clib-0.2.12-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (739 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m739.1/739.1 kB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ruamel.yaml.clib, ruamel.yaml, hyperpyyaml, speechbrain\n",
            "Successfully installed hyperpyyaml-1.2.2 ruamel.yaml-0.18.10 ruamel.yaml.clib-0.2.12 speechbrain-0.5.14\n",
            "Collecting audiomentations==0.33.0\n",
            "  Downloading audiomentations-0.33.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.11/dist-packages (from audiomentations==0.33.0) (1.26.4)\n",
            "Requirement already satisfied: librosa!=0.10.0,<0.11.0,>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from audiomentations==0.33.0) (0.10.2.post1)\n",
            "Requirement already satisfied: scipy<2,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from audiomentations==0.33.0) (1.13.1)\n",
            "Requirement already satisfied: soxr<1.0.0,>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from audiomentations==0.33.0) (0.5.0.post1)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations==0.33.0) (3.0.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations==0.33.0) (1.6.1)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.11/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations==0.33.0) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations==0.33.0) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations==0.33.0) (0.61.0)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations==0.33.0) (0.13.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations==0.33.0) (1.8.2)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations==0.33.0) (4.12.2)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations==0.33.0) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations==0.33.0) (1.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from lazy-loader>=0.1->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations==0.33.0) (24.2)\n",
            "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations==0.33.0) (0.44.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations==0.33.0) (4.3.6)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations==0.33.0) (2.32.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.20.0->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations==0.33.0) (3.5.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.1->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations==0.33.0) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations==0.33.0) (2.22)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations==0.33.0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations==0.33.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations==0.33.0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations==0.33.0) (2025.1.31)\n",
            "Downloading audiomentations-0.33.0-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.8/76.8 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: audiomentations\n",
            "Successfully installed audiomentations-0.33.0\n",
            "Collecting torch-audiomentations==0.11.0\n",
            "  Downloading torch_audiomentations-0.11.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting julius<0.3,>=0.2.3 (from torch-audiomentations==0.11.0)\n",
            "  Downloading julius-0.2.7.tar.gz (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.6/59.6 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: librosa>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from torch-audiomentations==0.11.0) (0.10.2.post1)\n",
            "Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from torch-audiomentations==0.11.0) (2.5.1+cu124)\n",
            "Requirement already satisfied: torchaudio>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from torch-audiomentations==0.11.0) (2.5.1+cu124)\n",
            "Collecting torch-pitch-shift>=1.2.2 (from torch-audiomentations==0.11.0)\n",
            "  Downloading torch_pitch_shift-1.2.5-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.6.0->torch-audiomentations==0.11.0) (3.0.1)\n",
            "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.6.0->torch-audiomentations==0.11.0) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.6.0->torch-audiomentations==0.11.0) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.6.0->torch-audiomentations==0.11.0) (1.6.1)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.6.0->torch-audiomentations==0.11.0) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.6.0->torch-audiomentations==0.11.0) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.6.0->torch-audiomentations==0.11.0) (0.61.0)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.6.0->torch-audiomentations==0.11.0) (0.13.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.6.0->torch-audiomentations==0.11.0) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.6.0->torch-audiomentations==0.11.0) (0.5.0.post1)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.6.0->torch-audiomentations==0.11.0) (4.12.2)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.6.0->torch-audiomentations==0.11.0) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.6.0->torch-audiomentations==0.11.0) (1.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->torch-audiomentations==0.11.0) (3.17.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->torch-audiomentations==0.11.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->torch-audiomentations==0.11.0) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->torch-audiomentations==0.11.0) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->torch-audiomentations==0.11.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->torch-audiomentations==0.11.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->torch-audiomentations==0.11.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->torch-audiomentations==0.11.0) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->torch-audiomentations==0.11.0) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->torch-audiomentations==0.11.0) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->torch-audiomentations==0.11.0) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->torch-audiomentations==0.11.0) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->torch-audiomentations==0.11.0) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->torch-audiomentations==0.11.0) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->torch-audiomentations==0.11.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->torch-audiomentations==0.11.0) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->torch-audiomentations==0.11.0) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->torch-audiomentations==0.11.0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.7.0->torch-audiomentations==0.11.0) (1.3.0)\n",
            "Collecting primePy>=1.3 (from torch-pitch-shift>=1.2.2->torch-audiomentations==0.11.0)\n",
            "  Downloading primePy-1.3-py3-none-any.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from torch-pitch-shift>=1.2.2->torch-audiomentations==0.11.0) (24.2)\n",
            "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa>=0.6.0->torch-audiomentations==0.11.0) (0.44.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa>=0.6.0->torch-audiomentations==0.11.0) (4.3.6)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa>=0.6.0->torch-audiomentations==0.11.0) (2.32.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.20.0->librosa>=0.6.0->torch-audiomentations==0.11.0) (3.5.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.1->librosa>=0.6.0->torch-audiomentations==0.11.0) (1.17.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.7.0->torch-audiomentations==0.11.0) (3.0.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa>=0.6.0->torch-audiomentations==0.11.0) (2.22)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa>=0.6.0->torch-audiomentations==0.11.0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa>=0.6.0->torch-audiomentations==0.11.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa>=0.6.0->torch-audiomentations==0.11.0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa>=0.6.0->torch-audiomentations==0.11.0) (2025.1.31)\n",
            "Downloading torch_audiomentations-0.11.0-py3-none-any.whl (47 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.9/47.9 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch_pitch_shift-1.2.5-py3-none-any.whl (5.0 kB)\n",
            "Downloading primePy-1.3-py3-none-any.whl (4.0 kB)\n",
            "Building wheels for collected packages: julius\n",
            "  Building wheel for julius (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for julius: filename=julius-0.2.7-py3-none-any.whl size=21869 sha256=5f554bd35331d5498aa54fe250e707338e92a5dd6c1aeae37090b46ada43364b\n",
            "  Stored in directory: /root/.cache/pip/wheels/16/15/d4/edd724cefe78050a6ba3344b8b0c6672db829a799dbb9f81ff\n",
            "Successfully built julius\n",
            "Installing collected packages: primePy, julius, torch-pitch-shift, torch-audiomentations\n",
            "Successfully installed julius-0.2.7 primePy-1.3 torch-audiomentations-0.11.0 torch-pitch-shift-1.2.5\n",
            "Collecting acoustics==0.2.6\n",
            "  Downloading acoustics-0.2.6.tar.gz (3.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m47.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.8 in /usr/local/lib/python3.11/dist-packages (from acoustics==0.2.6) (1.26.4)\n",
            "Requirement already satisfied: scipy>=0.16 in /usr/local/lib/python3.11/dist-packages (from acoustics==0.2.6) (1.13.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from acoustics==0.2.6) (3.10.0)\n",
            "Requirement already satisfied: six>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from acoustics==0.2.6) (1.17.0)\n",
            "Requirement already satisfied: pandas>=0.15 in /usr/local/lib/python3.11/dist-packages (from acoustics==0.2.6) (2.2.2)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.11/dist-packages (from acoustics==0.2.6) (0.9.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.15->acoustics==0.2.6) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.15->acoustics==0.2.6) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.15->acoustics==0.2.6) (2025.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->acoustics==0.2.6) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->acoustics==0.2.6) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->acoustics==0.2.6) (4.55.8)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->acoustics==0.2.6) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->acoustics==0.2.6) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->acoustics==0.2.6) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->acoustics==0.2.6) (3.2.1)\n",
            "Building wheels for collected packages: acoustics\n",
            "  Building wheel for acoustics (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for acoustics: filename=acoustics-0.2.6-py3-none-any.whl size=68183 sha256=f7c54d4d62fa728f9a84f7ae729335de473a1dd17cde0ad0a5f2aac98a57935a\n",
            "  Stored in directory: /root/.cache/pip/wheels/44/f0/b5/30a5d47708560f77b9167961c7ce13ab1ecf6ac352a3c077c2\n",
            "Successfully built acoustics\n",
            "Installing collected packages: acoustics\n",
            "Successfully installed acoustics-0.2.6\n",
            "Found existing installation: tensorflow 2.18.0\n",
            "Uninstalling tensorflow-2.18.0:\n",
            "  Successfully uninstalled tensorflow-2.18.0\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement tensorflow-cpu==2.8.1 (from versions: 2.12.0rc0, 2.12.0rc1, 2.12.0, 2.12.1, 2.13.0rc0, 2.13.0rc1, 2.13.0rc2, 2.13.0, 2.13.1, 2.14.0rc0, 2.14.0rc1, 2.14.0, 2.14.1, 2.15.0rc0, 2.15.0rc1, 2.15.0, 2.15.0.post1, 2.15.1, 2.16.0rc0, 2.16.1, 2.16.2, 2.17.0rc0, 2.17.0rc1, 2.17.0, 2.17.1, 2.18.0rc0, 2.18.0rc1, 2.18.0rc2, 2.18.0)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for tensorflow-cpu==2.8.1\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting tensorflow_probability==0.16.0\n",
            "  Downloading tensorflow_probability-0.16.0-py2.py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from tensorflow_probability==0.16.0) (1.4.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow_probability==0.16.0) (1.17.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow_probability==0.16.0) (1.26.4)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from tensorflow_probability==0.16.0) (4.4.2)\n",
            "Requirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow_probability==0.16.0) (3.1.1)\n",
            "Requirement already satisfied: gast>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow_probability==0.16.0) (0.6.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.11/dist-packages (from tensorflow_probability==0.16.0) (0.1.9)\n",
            "Requirement already satisfied: attrs>=18.2.0 in /usr/local/lib/python3.11/dist-packages (from dm-tree->tensorflow_probability==0.16.0) (25.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.2 in /usr/local/lib/python3.11/dist-packages (from dm-tree->tensorflow_probability==0.16.0) (1.17.2)\n",
            "Downloading tensorflow_probability-0.16.0-py2.py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m35.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tensorflow_probability\n",
            "  Attempting uninstall: tensorflow_probability\n",
            "    Found existing installation: tensorflow-probability 0.25.0\n",
            "    Uninstalling tensorflow-probability-0.25.0:\n",
            "      Successfully uninstalled tensorflow-probability-0.25.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "dopamine-rl 4.1.2 requires tensorflow>=2.2.0, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed tensorflow_probability-0.16.0\n",
            "Collecting onnx_tf==1.10.0\n",
            "  Downloading onnx_tf-1.10.0-py3-none-any.whl.metadata (510 bytes)\n",
            "Collecting onnx>=1.10.2 (from onnx_tf==1.10.0)\n",
            "  Downloading onnx-1.17.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from onnx_tf==1.10.0) (6.0.2)\n",
            "Collecting tensorflow-addons (from onnx_tf==1.10.0)\n",
            "  Downloading tensorflow_addons-0.23.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.11/dist-packages (from onnx>=1.10.2->onnx_tf==1.10.0) (1.26.4)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from onnx>=1.10.2->onnx_tf==1.10.0) (4.25.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow-addons->onnx_tf==1.10.0) (24.2)\n",
            "Collecting typeguard<3.0.0,>=2.7 (from tensorflow-addons->onnx_tf==1.10.0)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl.metadata (3.6 kB)\n",
            "Downloading onnx_tf-1.10.0-py3-none-any.whl (226 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.1/226.1 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnx-1.17.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m77.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_addons-0.23.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (611 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.8/611.8 kB\u001b[0m \u001b[31m35.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: typeguard, onnx, tensorflow-addons, onnx_tf\n",
            "  Attempting uninstall: typeguard\n",
            "    Found existing installation: typeguard 4.4.1\n",
            "    Uninstalling typeguard-4.4.1:\n",
            "      Successfully uninstalled typeguard-4.4.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "inflect 7.5.0 requires typeguard>=4.0.1, but you have typeguard 2.13.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed onnx-1.17.0 onnx_tf-1.10.0 tensorflow-addons-0.23.0 typeguard-2.13.3\n",
            "Collecting pronouncing==0.2.0\n",
            "  Downloading pronouncing-0.2.0.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting cmudict>=0.4.0 (from pronouncing==0.2.0)\n",
            "  Downloading cmudict-1.0.32-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: importlib-metadata>=5 in /usr/local/lib/python3.11/dist-packages (from cmudict>=0.4.0->pronouncing==0.2.0) (8.6.1)\n",
            "Requirement already satisfied: importlib-resources>=5 in /usr/local/lib/python3.11/dist-packages (from cmudict>=0.4.0->pronouncing==0.2.0) (6.5.2)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata>=5->cmudict>=0.4.0->pronouncing==0.2.0) (3.21.0)\n",
            "Downloading cmudict-1.0.32-py3-none-any.whl (939 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m939.4/939.4 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pronouncing\n",
            "  Building wheel for pronouncing (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pronouncing: filename=pronouncing-0.2.0-py2.py3-none-any.whl size=6233 sha256=facf68bd7102706d849bc5a9e0dc12cda36c0f1288b18073ede3788f2f1dae16\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/81/fd/7edbf09827c7a7e2666e870b4c5c6b46c7ebd5defa399698bd\n",
            "Successfully built pronouncing\n",
            "Installing collected packages: cmudict, pronouncing\n",
            "Successfully installed cmudict-1.0.32 pronouncing-0.2.0\n",
            "Collecting datasets==2.14.6\n",
            "  Downloading datasets-2.14.6-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets==2.14.6) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets==2.14.6) (17.0.0)\n",
            "Collecting dill<0.3.8,>=0.3.0 (from datasets==2.14.6)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets==2.14.6) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from datasets==2.14.6) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from datasets==2.14.6) (4.67.1)\n",
            "Collecting xxhash (from datasets==2.14.6)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess (from datasets==2.14.6)\n",
            "  Downloading multiprocess-0.70.17-py311-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2023.10.0,>=2023.1.0 (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets==2.14.6)\n",
            "  Downloading fsspec-2023.10.0-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets==2.14.6) (3.11.12)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from datasets==2.14.6) (0.28.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets==2.14.6) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets==2.14.6) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.14.6) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.14.6) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.14.6) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.14.6) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.14.6) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.14.6) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.14.6) (1.18.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets==2.14.6) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets==2.14.6) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets==2.14.6) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets==2.14.6) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets==2.14.6) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets==2.14.6) (2025.1.31)\n",
            "INFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting multiprocess (from datasets==2.14.6)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "  Downloading multiprocess-0.70.15-py311-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==2.14.6) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==2.14.6) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==2.14.6) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets==2.14.6) (1.17.0)\n",
            "Downloading datasets-2.14.6-py3-none-any.whl (493 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m493.7/493.7 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2023.10.0-py3-none-any.whl (166 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.4/166.4 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.15-py311-none-any.whl (135 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.4/135.4 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2023.10.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-2.14.6 dill-0.3.7 fsspec-2023.10.0 multiprocess-0.70.15 xxhash-3.5.0\n",
            "Collecting deep-phonemizer==0.0.19\n",
            "  Downloading deep-phonemizer-0.0.19.tar.gz (29 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from deep-phonemizer==0.0.19) (2.5.1+cu124)\n",
            "Requirement already satisfied: tqdm>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from deep-phonemizer==0.0.19) (4.67.1)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from deep-phonemizer==0.0.19) (6.0.2)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.11/dist-packages (from deep-phonemizer==0.0.19) (2.18.0)\n",
            "Requirement already satisfied: certifi>=2022.12.7 in /usr/local/lib/python3.11/dist-packages (from deep-phonemizer==0.0.19) (2025.1.31)\n",
            "Requirement already satisfied: wheel>=0.38.0 in /usr/local/lib/python3.11/dist-packages (from deep-phonemizer==0.0.19) (0.45.1)\n",
            "Requirement already satisfied: setuptools>=65.5.1 in /usr/local/lib/python3.11/dist-packages (from deep-phonemizer==0.0.19) (75.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->deep-phonemizer==0.0.19) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->deep-phonemizer==0.0.19) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->deep-phonemizer==0.0.19) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->deep-phonemizer==0.0.19) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->deep-phonemizer==0.0.19) (2023.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->deep-phonemizer==0.0.19) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->deep-phonemizer==0.0.19) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->deep-phonemizer==0.0.19) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->deep-phonemizer==0.0.19) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->deep-phonemizer==0.0.19) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->deep-phonemizer==0.0.19) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->deep-phonemizer==0.0.19) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->deep-phonemizer==0.0.19) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->deep-phonemizer==0.0.19) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->deep-phonemizer==0.0.19) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->deep-phonemizer==0.0.19) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->deep-phonemizer==0.0.19) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->deep-phonemizer==0.0.19) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->deep-phonemizer==0.0.19) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.2.0->deep-phonemizer==0.0.19) (1.3.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard->deep-phonemizer==0.0.19) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard->deep-phonemizer==0.0.19) (1.70.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard->deep-phonemizer==0.0.19) (3.7)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard->deep-phonemizer==0.0.19) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorboard->deep-phonemizer==0.0.19) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard->deep-phonemizer==0.0.19) (4.25.6)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard->deep-phonemizer==0.0.19) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard->deep-phonemizer==0.0.19) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard->deep-phonemizer==0.0.19) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard->deep-phonemizer==0.0.19) (3.0.2)\n",
            "Building wheels for collected packages: deep-phonemizer\n",
            "  Building wheel for deep-phonemizer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for deep-phonemizer: filename=deep_phonemizer-0.0.19-py3-none-any.whl size=33273 sha256=52e97ce29b0b2bc7964a43aa174c0f4cc9efd5f370078d919aaddef4ac6f55f9\n",
            "  Stored in directory: /root/.cache/pip/wheels/73/cc/01/1c74a1f4e6ba31a42bb82f4e3d852e2f23236fe3e5d589dcf3\n",
            "Successfully built deep-phonemizer\n",
            "Installing collected packages: deep-phonemizer\n",
            "Successfully installed deep-phonemizer-0.0.19\n",
            "--2025-02-13 19:41:28--  https://github.com/dscripka/openWakeWord/releases/download/v0.5.1/embedding_model.onnx\n",
            "Resolving github.com (github.com)... 140.82.113.3\n",
            "Connecting to github.com (github.com)|140.82.113.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/497407399/0233db07-b8db-4fc3-b026-b75d77fd7ae6?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250213%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250213T194128Z&X-Amz-Expires=300&X-Amz-Signature=9ca033d68896a5f3ddfe5f459b47ff8ef65e191fc573424c946f019c30fb9389&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dembedding_model.onnx&response-content-type=application%2Foctet-stream [following]\n",
            "--2025-02-13 19:41:28--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/497407399/0233db07-b8db-4fc3-b026-b75d77fd7ae6?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250213%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250213T194128Z&X-Amz-Expires=300&X-Amz-Signature=9ca033d68896a5f3ddfe5f459b47ff8ef65e191fc573424c946f019c30fb9389&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dembedding_model.onnx&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1326578 (1.3M) [application/octet-stream]\n",
            "Saving to: ‘./openwakeword/openwakeword/resources/models/embedding_model.onnx’\n",
            "\n",
            "./openwakeword/open 100%[===================>]   1.26M  --.-KB/s    in 0.05s   \n",
            "\n",
            "2025-02-13 19:41:28 (28.1 MB/s) - ‘./openwakeword/openwakeword/resources/models/embedding_model.onnx’ saved [1326578/1326578]\n",
            "\n",
            "--2025-02-13 19:41:28--  https://github.com/dscripka/openWakeWord/releases/download/v0.5.1/embedding_model.tflite\n",
            "Resolving github.com (github.com)... 140.82.113.3\n",
            "Connecting to github.com (github.com)|140.82.113.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/497407399/4bfa8f05-dd30-45f6-b47c-c55548bb5ffc?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250213%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250213T194129Z&X-Amz-Expires=300&X-Amz-Signature=536852fab11df2c200a0c373983c056e4edc4cf8e01e028f669b7f7a7d69d420&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dembedding_model.tflite&response-content-type=application%2Foctet-stream [following]\n",
            "--2025-02-13 19:41:29--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/497407399/4bfa8f05-dd30-45f6-b47c-c55548bb5ffc?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250213%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250213T194129Z&X-Amz-Expires=300&X-Amz-Signature=536852fab11df2c200a0c373983c056e4edc4cf8e01e028f669b7f7a7d69d420&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dembedding_model.tflite&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1330312 (1.3M) [application/octet-stream]\n",
            "Saving to: ‘./openwakeword/openwakeword/resources/models/embedding_model.tflite’\n",
            "\n",
            "./openwakeword/open 100%[===================>]   1.27M  --.-KB/s    in 0.05s   \n",
            "\n",
            "2025-02-13 19:41:29 (26.5 MB/s) - ‘./openwakeword/openwakeword/resources/models/embedding_model.tflite’ saved [1330312/1330312]\n",
            "\n",
            "--2025-02-13 19:41:29--  https://github.com/dscripka/openWakeWord/releases/download/v0.5.1/melspectrogram.onnx\n",
            "Resolving github.com (github.com)... 140.82.114.4\n",
            "Connecting to github.com (github.com)|140.82.114.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/497407399/6b613c12-b693-4220-82d5-01be396893d9?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250213%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250213T194130Z&X-Amz-Expires=300&X-Amz-Signature=1ed37ab07d00d044113a0ce2863f06d42f32620ca1035ffa499eeee57b2e2a79&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dmelspectrogram.onnx&response-content-type=application%2Foctet-stream [following]\n",
            "--2025-02-13 19:41:30--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/497407399/6b613c12-b693-4220-82d5-01be396893d9?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250213%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250213T194130Z&X-Amz-Expires=300&X-Amz-Signature=1ed37ab07d00d044113a0ce2863f06d42f32620ca1035ffa499eeee57b2e2a79&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dmelspectrogram.onnx&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1087958 (1.0M) [application/octet-stream]\n",
            "Saving to: ‘./openwakeword/openwakeword/resources/models/melspectrogram.onnx’\n",
            "\n",
            "./openwakeword/open 100%[===================>]   1.04M  --.-KB/s    in 0.04s   \n",
            "\n",
            "2025-02-13 19:41:30 (25.2 MB/s) - ‘./openwakeword/openwakeword/resources/models/melspectrogram.onnx’ saved [1087958/1087958]\n",
            "\n",
            "--2025-02-13 19:41:30--  https://github.com/dscripka/openWakeWord/releases/download/v0.5.1/melspectrogram.tflite\n",
            "Resolving github.com (github.com)... 140.82.112.4\n",
            "Connecting to github.com (github.com)|140.82.112.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/497407399/14a5e610-f7fa-4157-ae44-fdaabf875683?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250213%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250213T194130Z&X-Amz-Expires=300&X-Amz-Signature=06838c94950efa28a71e47ee03394785f333a572019fa8c67d17d418560243a3&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dmelspectrogram.tflite&response-content-type=application%2Foctet-stream [following]\n",
            "--2025-02-13 19:41:30--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/497407399/14a5e610-f7fa-4157-ae44-fdaabf875683?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250213%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250213T194130Z&X-Amz-Expires=300&X-Amz-Signature=06838c94950efa28a71e47ee03394785f333a572019fa8c67d17d418560243a3&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dmelspectrogram.tflite&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1092516 (1.0M) [application/octet-stream]\n",
            "Saving to: ‘./openwakeword/openwakeword/resources/models/melspectrogram.tflite’\n",
            "\n",
            "./openwakeword/open 100%[===================>]   1.04M  --.-KB/s    in 0.04s   \n",
            "\n",
            "2025-02-13 19:41:30 (25.0 MB/s) - ‘./openwakeword/openwakeword/resources/models/melspectrogram.tflite’ saved [1092516/1092516]\n",
            "\n",
            "Git LFS initialized.\n",
            "Cloning into 'MIT_environmental_impulse_responses'...\n",
            "remote: Enumerating objects: 280, done.\u001b[K\n",
            "remote: Total 280 (delta 0), reused 0 (delta 0), pack-reused 280 (from 1)\u001b[K\n",
            "Receiving objects: 100% (280/280), 41.11 KiB | 5.87 MiB/s, done.\n",
            "Resolving deltas: 100% (1/1), done.\n",
            "Filtering content: 100% (270/270), 7.99 MiB | 1.30 MiB/s, done.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 270/270 [00:29<00:00,  9.11it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2025-02-13 19:42:11--  https://huggingface.co/datasets/agkphysics/AudioSet/resolve/main/bal_train09.tar\n",
            "Resolving huggingface.co (huggingface.co)... 18.164.174.17, 18.164.174.55, 18.164.174.118, ...\n",
            "Connecting to huggingface.co (huggingface.co)|18.164.174.17|:443... connected.\n",
            "HTTP request sent, awaiting response... 404 Not Found\n",
            "2025-02-13 19:42:11 ERROR 404: Not Found.\n",
            "\n",
            "tar: This does not look like a tar archive\n",
            "tar: Exiting with failure status due to previous errors\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "0it [00:00, ?it/s]\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9e7b5702f4f34efa91ed2b2b3fabd62b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/46.3k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "28b901e22b93410b8e7a2358d1cd8005",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 99%|█████████▉| 119/120 [00:56<00:00,  2.11it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2025-02-13 19:43:57--  https://huggingface.co/datasets/davidscripka/openwakeword_features/resolve/main/openwakeword_features_ACAV100M_2000_hrs_16bit.npy\n",
            "Resolving huggingface.co (huggingface.co)... 18.164.174.17, 18.164.174.23, 18.164.174.118, ...\n",
            "Connecting to huggingface.co (huggingface.co)|18.164.174.17|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs.hf.co/repos/a4/6f/a46f490589856ef0544c988c81f74c322707464d95ce7128c9df5f54295be163/721a66d0682c65a1b5c1da0aa109409cede1d20e28b15235c344b000cbb7654f?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27openwakeword_features_ACAV100M_2000_hrs_16bit.npy%3B+filename%3D%22openwakeword_features_ACAV100M_2000_hrs_16bit.npy%22%3B&Expires=1739479437&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczOTQ3OTQzN319LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9yZXBvcy9hNC82Zi9hNDZmNDkwNTg5ODU2ZWYwNTQ0Yzk4OGM4MWY3NGMzMjI3MDc0NjRkOTVjZTcxMjhjOWRmNWY1NDI5NWJlMTYzLzcyMWE2NmQwNjgyYzY1YTFiNWMxZGEwYWExMDk0MDljZWRlMWQyMGUyOGIxNTIzNWMzNDRiMDAwY2JiNzY1NGY%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=kw4nI1Ti%7E9Hx3SQYdifhBUx9lDc393%7EwOPFLiOJ7OtcgoMC7vHBObsOoEmK4Av10REPe8gTL30Q2-4YmrdRvgv2fYlbI4lqTVdpaF3SVo29LdeAr6ztu5BLIDMqO9imSWhGugCVOZfA9tS3Q1oKa08MBUZINj5a8i6iuVeiEJ1kj-AM5Z30pvSAZC1SshY9jUE8%7ESEfNN59B1w8TWOTys7hYJy2duWWT91xkQ7lD6zO%7EqBLmgkczKx8wROVkMyd%7EO6uS1wrE1ZYYEkRUZVSB4c0L7nBwe-OZYSpfvDjj5P3BgtD%7Ech5cKpNw2WcIQfWvJHZ7jf1N%7EWHyVOUrMCNGtQ__&Key-Pair-Id=K3RPWS32NSSJCE [following]\n",
            "--2025-02-13 19:43:57--  https://cdn-lfs.hf.co/repos/a4/6f/a46f490589856ef0544c988c81f74c322707464d95ce7128c9df5f54295be163/721a66d0682c65a1b5c1da0aa109409cede1d20e28b15235c344b000cbb7654f?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27openwakeword_features_ACAV100M_2000_hrs_16bit.npy%3B+filename%3D%22openwakeword_features_ACAV100M_2000_hrs_16bit.npy%22%3B&Expires=1739479437&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczOTQ3OTQzN319LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9yZXBvcy9hNC82Zi9hNDZmNDkwNTg5ODU2ZWYwNTQ0Yzk4OGM4MWY3NGMzMjI3MDc0NjRkOTVjZTcxMjhjOWRmNWY1NDI5NWJlMTYzLzcyMWE2NmQwNjgyYzY1YTFiNWMxZGEwYWExMDk0MDljZWRlMWQyMGUyOGIxNTIzNWMzNDRiMDAwY2JiNzY1NGY%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=kw4nI1Ti%7E9Hx3SQYdifhBUx9lDc393%7EwOPFLiOJ7OtcgoMC7vHBObsOoEmK4Av10REPe8gTL30Q2-4YmrdRvgv2fYlbI4lqTVdpaF3SVo29LdeAr6ztu5BLIDMqO9imSWhGugCVOZfA9tS3Q1oKa08MBUZINj5a8i6iuVeiEJ1kj-AM5Z30pvSAZC1SshY9jUE8%7ESEfNN59B1w8TWOTys7hYJy2duWWT91xkQ7lD6zO%7EqBLmgkczKx8wROVkMyd%7EO6uS1wrE1ZYYEkRUZVSB4c0L7nBwe-OZYSpfvDjj5P3BgtD%7Ech5cKpNw2WcIQfWvJHZ7jf1N%7EWHyVOUrMCNGtQ__&Key-Pair-Id=K3RPWS32NSSJCE\n",
            "Resolving cdn-lfs.hf.co (cdn-lfs.hf.co)... 3.168.132.48, 3.168.132.99, 3.168.132.51, ...\n",
            "Connecting to cdn-lfs.hf.co (cdn-lfs.hf.co)|3.168.132.48|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 17280000128 (16G) [binary/octet-stream]\n",
            "Saving to: ‘openwakeword_features_ACAV100M_2000_hrs_16bit.npy’\n",
            "\n",
            "openwakeword_featur 100%[===================>]  16.09G   226MB/s    in 2m 3s   \n",
            "\n",
            "2025-02-13 19:46:00 (134 MB/s) - ‘openwakeword_features_ACAV100M_2000_hrs_16bit.npy’ saved [17280000128/17280000128]\n",
            "\n",
            "--2025-02-13 19:46:00--  https://huggingface.co/datasets/davidscripka/openwakeword_features/resolve/main/validation_set_features.npy\n",
            "Resolving huggingface.co (huggingface.co)... 18.164.174.118, 18.164.174.17, 18.164.174.55, ...\n",
            "Connecting to huggingface.co (huggingface.co)|18.164.174.118|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs.hf.co/repos/a4/6f/a46f490589856ef0544c988c81f74c322707464d95ce7128c9df5f54295be163/a56a8a0f8e0efb91900acc6de4c0cdf4c564842e8475a7d49b36c039e17a690f?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27validation_set_features.npy%3B+filename%3D%22validation_set_features.npy%22%3B&Expires=1739479560&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczOTQ3OTU2MH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9yZXBvcy9hNC82Zi9hNDZmNDkwNTg5ODU2ZWYwNTQ0Yzk4OGM4MWY3NGMzMjI3MDc0NjRkOTVjZTcxMjhjOWRmNWY1NDI5NWJlMTYzL2E1NmE4YTBmOGUwZWZiOTE5MDBhY2M2ZGU0YzBjZGY0YzU2NDg0MmU4NDc1YTdkNDliMzZjMDM5ZTE3YTY5MGY%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=hmUX7HMCKLlhkw0wywXS-fKWAfd52GX2Z5xnFQrjPg-SlKb4Xbiw61rYj1hUKorVglEqtsv30t000FyAFbvVEyVbWctShvHSeHmAXZkzfFAR5iLyZyBo9TFG9x8T%7EVnUj-b8WuriHhl9zSquyYIpP4cd7jJqilySmNY6lJxq1slrVdo7lsQo3NQNb-Lyaks2YSL8PGUBm2oIFo1xmtGu80IvS1Gu42mC02FIQ3zfQmgDz2RH0%7Eo9UG6d609Xkz0Lgk11Hsz3uIFcrE2Ind7wl8yqJ13X7Y%7E6AteYYyPTCMou0uywVy0fbsQrFy%7EYeuzod0Fv%7End0ot37kBpKB9KCxg__&Key-Pair-Id=K3RPWS32NSSJCE [following]\n",
            "--2025-02-13 19:46:00--  https://cdn-lfs.hf.co/repos/a4/6f/a46f490589856ef0544c988c81f74c322707464d95ce7128c9df5f54295be163/a56a8a0f8e0efb91900acc6de4c0cdf4c564842e8475a7d49b36c039e17a690f?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27validation_set_features.npy%3B+filename%3D%22validation_set_features.npy%22%3B&Expires=1739479560&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczOTQ3OTU2MH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9yZXBvcy9hNC82Zi9hNDZmNDkwNTg5ODU2ZWYwNTQ0Yzk4OGM4MWY3NGMzMjI3MDc0NjRkOTVjZTcxMjhjOWRmNWY1NDI5NWJlMTYzL2E1NmE4YTBmOGUwZWZiOTE5MDBhY2M2ZGU0YzBjZGY0YzU2NDg0MmU4NDc1YTdkNDliMzZjMDM5ZTE3YTY5MGY%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=hmUX7HMCKLlhkw0wywXS-fKWAfd52GX2Z5xnFQrjPg-SlKb4Xbiw61rYj1hUKorVglEqtsv30t000FyAFbvVEyVbWctShvHSeHmAXZkzfFAR5iLyZyBo9TFG9x8T%7EVnUj-b8WuriHhl9zSquyYIpP4cd7jJqilySmNY6lJxq1slrVdo7lsQo3NQNb-Lyaks2YSL8PGUBm2oIFo1xmtGu80IvS1Gu42mC02FIQ3zfQmgDz2RH0%7Eo9UG6d609Xkz0Lgk11Hsz3uIFcrE2Ind7wl8yqJ13X7Y%7E6AteYYyPTCMou0uywVy0fbsQrFy%7EYeuzod0Fv%7End0ot37kBpKB9KCxg__&Key-Pair-Id=K3RPWS32NSSJCE\n",
            "Resolving cdn-lfs.hf.co (cdn-lfs.hf.co)... 3.168.132.25, 3.168.132.48, 3.168.132.99, ...\n",
            "Connecting to cdn-lfs.hf.co (cdn-lfs.hf.co)|3.168.132.25|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 184836608 (176M) [binary/octet-stream]\n",
            "Saving to: ‘validation_set_features.npy’\n",
            "\n",
            "validation_set_feat 100%[===================>] 176.27M   124MB/s    in 1.4s    \n",
            "\n",
            "2025-02-13 19:46:02 (124 MB/s) - ‘validation_set_features.npy’ saved [184836608/184836608]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# @title  { display-mode: \"form\" }\n",
        "# @markdown # 2. Download Data\n",
        "# @markdown Training custom models requires downloading a wide variety of data\n",
        "# @markdown that will help make the model perform well in real-world scenarios.\n",
        "# @markdown This example notebook will download small samples of background noise,\n",
        "# @markdown music, and Room Impulse Responses (to add echo). This will still produce\n",
        "# @markdown a custom model that performs well, but if you are interested in adding even more,\n",
        "# @markdown feel free to extend this notebook to download the full datasets and even add\n",
        "# @markdown your own!\n",
        "# @markdown\n",
        "# @markdown Downloading this example data will usually take about 15 minutes.\n",
        "\n",
        "# @markdown **Important note!** The data downloaded here has a mixture of difference\n",
        "# @markdown licenses and usage restrictions. As such, any custom models trained with this\n",
        "# @markdown data should be considered as appropriate for **non-commercial** personal use only.\n",
        "\n",
        "# ## Install all dependencies\n",
        "# !pip install datasets\n",
        "# !pip install scipy\n",
        "# !pip install tqdm\n",
        "\n",
        "import locale\n",
        "def getpreferredencoding(do_setlocale = True):\n",
        "    return \"UTF-8\"\n",
        "locale.getpreferredencoding = getpreferredencoding\n",
        "\n",
        "# install openwakeword (full installation to support training)\n",
        "!git clone https://github.com/dscripka/openwakeword\n",
        "!pip install -e ./openwakeword\n",
        "!cd openwakeword\n",
        "\n",
        "# install other dependencies\n",
        "!pip install mutagen==1.47.0\n",
        "!pip install torchinfo==1.8.0\n",
        "!pip install torchmetrics==1.2.0\n",
        "!pip install speechbrain==0.5.14\n",
        "!pip install audiomentations==0.33.0\n",
        "!pip install torch-audiomentations==0.11.0\n",
        "!pip install acoustics==0.2.6\n",
        "!pip uninstall tensorflow -y\n",
        "!pip install tensorflow-cpu==2.8.1\n",
        "!pip install tensorflow_probability==0.16.0\n",
        "!pip install onnx_tf==1.10.0\n",
        "!pip install pronouncing==0.2.0\n",
        "!pip install datasets==2.14.6\n",
        "!pip install deep-phonemizer==0.0.19\n",
        "\n",
        "# Download required models (workaround for Colab)\n",
        "import os\n",
        "os.makedirs(\"./openwakeword/openwakeword/resources/models\")\n",
        "!wget https://github.com/dscripka/openWakeWord/releases/download/v0.5.1/embedding_model.onnx -O ./openwakeword/openwakeword/resources/models/embedding_model.onnx\n",
        "!wget https://github.com/dscripka/openWakeWord/releases/download/v0.5.1/embedding_model.tflite -O ./openwakeword/openwakeword/resources/models/embedding_model.tflite\n",
        "!wget https://github.com/dscripka/openWakeWord/releases/download/v0.5.1/melspectrogram.onnx -O ./openwakeword/openwakeword/resources/models/melspectrogram.onnx\n",
        "!wget https://github.com/dscripka/openWakeWord/releases/download/v0.5.1/melspectrogram.tflite -O ./openwakeword/openwakeword/resources/models/melspectrogram.tflite\n",
        "\n",
        "# Imports\n",
        "import sys\n",
        "\n",
        "if \"piper-sample-generator/\" not in sys.path:\n",
        "    sys.path.append(\"piper-sample-generator/\")\n",
        "from generate_samples import generate_samples\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import sys\n",
        "from pathlib import Path\n",
        "import uuid\n",
        "import yaml\n",
        "import datasets\n",
        "import scipy\n",
        "from tqdm import tqdm\n",
        "\n",
        "## Download all data\n",
        "\n",
        "## Download MIR RIR data (takes about ~2 minutes)\n",
        "output_dir = \"./mit_rirs\"\n",
        "if not os.path.exists(output_dir):\n",
        "    os.mkdir(output_dir)\n",
        "    !git lfs install\n",
        "    !git clone https://huggingface.co/datasets/davidscripka/MIT_environmental_impulse_responses\n",
        "    rir_dataset = datasets.Dataset.from_dict({\"audio\": [str(i) for i in Path(\"./MIT_environmental_impulse_responses/16khz\").glob(\"*.wav\")]}).cast_column(\"audio\", datasets.Audio())\n",
        "    # Save clips to 16-bit PCM wav files\n",
        "    for row in tqdm(rir_dataset):\n",
        "        name = row['audio']['path'].split('/')[-1]\n",
        "        scipy.io.wavfile.write(os.path.join(output_dir, name), 16000, (row['audio']['array']*32767).astype(np.int16))\n",
        "\n",
        "## Download noise and background audio (takes about ~3 minutes)\n",
        "\n",
        "# Audioset Dataset (https://research.google.com/audioset/dataset/index.html)\n",
        "# Download one part of the audioset .tar files, extract, and convert to 16khz\n",
        "# For full-scale training, it's recommended to download the entire dataset from\n",
        "# https://huggingface.co/datasets/agkphysics/AudioSet, and\n",
        "# even potentially combine it with other background noise datasets (e.g., FSD50k, Freesound, etc.)\n",
        "\n",
        "if not os.path.exists(\"audioset\"):\n",
        "    os.mkdir(\"audioset\")\n",
        "\n",
        "    fname = \"bal_train09.tar\"\n",
        "    out_dir = f\"audioset/{fname}\"\n",
        "    link = \"https://huggingface.co/datasets/agkphysics/AudioSet/resolve/main/\" + fname\n",
        "    !wget -O {out_dir} {link}\n",
        "    !cd audioset && tar -xvf bal_train09.tar\n",
        "\n",
        "    output_dir = \"./audioset_16k\"\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.mkdir(output_dir)\n",
        "\n",
        "    # Save clips to 16-bit PCM wav files\n",
        "    audioset_dataset = datasets.Dataset.from_dict({\"audio\": [str(i) for i in Path(\"audioset/audio\").glob(\"**/*.flac\")]})\n",
        "    audioset_dataset = audioset_dataset.cast_column(\"audio\", datasets.Audio(sampling_rate=16000))\n",
        "    for row in tqdm(audioset_dataset):\n",
        "        name = row['audio']['path'].split('/')[-1].replace(\".flac\", \".wav\")\n",
        "        scipy.io.wavfile.write(os.path.join(output_dir, name), 16000, (row['audio']['array']*32767).astype(np.int16))\n",
        "\n",
        "# Free Music Archive dataset\n",
        "# https://github.com/mdeff/fma\n",
        "\n",
        "output_dir = \"./fma\"\n",
        "if not os.path.exists(output_dir):\n",
        "    os.mkdir(output_dir)\n",
        "    fma_dataset = datasets.load_dataset(\"rudraml/fma\", name=\"small\", split=\"train\", streaming=True)\n",
        "    fma_dataset = iter(fma_dataset.cast_column(\"audio\", datasets.Audio(sampling_rate=16000)))\n",
        "\n",
        "    # Save clips to 16-bit PCM wav files\n",
        "    n_hours = 1  # use only 1 hour of clips for this example notebook, recommend increasing for full-scale training\n",
        "    for i in tqdm(range(n_hours*3600//30)):  # this works because the FMA dataset is all 30 second clips\n",
        "        row = next(fma_dataset)\n",
        "        name = row['audio']['path'].split('/')[-1].replace(\".mp3\", \".wav\")\n",
        "        scipy.io.wavfile.write(os.path.join(output_dir, name), 16000, (row['audio']['array']*32767).astype(np.int16))\n",
        "        i += 1\n",
        "        if i == n_hours*3600//30:\n",
        "            break\n",
        "\n",
        "# Download pre-computed openWakeWord features for training and validation\n",
        "\n",
        "# training set (~2,000 hours from the ACAV100M Dataset)\n",
        "# See https://huggingface.co/datasets/davidscripka/openwakeword_features for more information\n",
        "if not os.path.exists(\"./openwakeword_features_ACAV100M_2000_hrs_16bit.npy\"):\n",
        "    !wget https://huggingface.co/datasets/davidscripka/openwakeword_features/resolve/main/openwakeword_features_ACAV100M_2000_hrs_16bit.npy\n",
        "\n",
        "# validation set for false positive rate estimation (~11 hours)\n",
        "if not os.path.exists(\"validation_set_features.npy\"):\n",
        "    !wget https://huggingface.co/datasets/davidscripka/openwakeword_features/resolve/main/validation_set_features.npy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qgaKWIY6WlJ1",
        "outputId": "f692548d-34b8-4744-d17d-73e353f281c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch_audiomentations/utils/io.py:27: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.\n",
            "  torchaudio.set_audio_backend(\"soundfile\")\n",
            "INFO:root:##################################################\n",
            "Generating positive clips for training\n",
            "##################################################\n",
            "DEBUG:generate_samples:Loading /content/piper-sample-generator/models/en_US-libritts_r-medium.pt\n",
            "/content/piper-sample-generator/generate_samples.py:76: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  torch_model = torch.load(model_path)\n",
            "INFO:generate_samples:Successfully loaded the model\n",
            "DEBUG:generate_samples:Batch 1/20 complete\n",
            "DEBUG:generate_samples:Batch 2/20 complete\n",
            "DEBUG:generate_samples:Batch 3/20 complete\n",
            "DEBUG:generate_samples:Batch 4/20 complete\n",
            "DEBUG:generate_samples:Batch 5/20 complete\n",
            "DEBUG:generate_samples:Batch 6/20 complete\n",
            "DEBUG:generate_samples:Batch 7/20 complete\n",
            "DEBUG:generate_samples:Batch 8/20 complete\n",
            "DEBUG:generate_samples:Batch 9/20 complete\n",
            "DEBUG:generate_samples:Batch 10/20 complete\n",
            "DEBUG:generate_samples:Batch 11/20 complete\n",
            "DEBUG:generate_samples:Batch 12/20 complete\n",
            "DEBUG:generate_samples:Batch 13/20 complete\n",
            "DEBUG:generate_samples:Batch 14/20 complete\n",
            "DEBUG:generate_samples:Batch 15/20 complete\n",
            "DEBUG:generate_samples:Batch 16/20 complete\n",
            "DEBUG:generate_samples:Batch 17/20 complete\n",
            "DEBUG:generate_samples:Batch 18/20 complete\n",
            "DEBUG:generate_samples:Batch 19/20 complete\n",
            "DEBUG:generate_samples:Batch 20/20 complete\n",
            "INFO:generate_samples:Done\n",
            "INFO:root:##################################################\n",
            "Generating positive clips for testing\n",
            "##################################################\n",
            "DEBUG:generate_samples:Loading /content/piper-sample-generator/models/en_US-libritts_r-medium.pt\n",
            "INFO:generate_samples:Successfully loaded the model\n",
            "DEBUG:generate_samples:Batch 1/10 complete\n",
            "DEBUG:generate_samples:Batch 2/10 complete\n",
            "DEBUG:generate_samples:Batch 3/10 complete\n",
            "DEBUG:generate_samples:Batch 4/10 complete\n",
            "DEBUG:generate_samples:Batch 5/10 complete\n",
            "DEBUG:generate_samples:Batch 6/10 complete\n",
            "DEBUG:generate_samples:Batch 7/10 complete\n",
            "DEBUG:generate_samples:Batch 8/10 complete\n",
            "DEBUG:generate_samples:Batch 9/10 complete\n",
            "DEBUG:generate_samples:Batch 10/10 complete\n",
            "INFO:generate_samples:Done\n",
            "INFO:root:##################################################\n",
            "Generating negative clips for training\n",
            "##################################################\n",
            "WARNING:root:Downloading phonemizer model from DeepPhonemizer library...\n",
            "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): public-asai-dl-models.s3.eu-central-1.amazonaws.com:443\n",
            "DEBUG:urllib3.connectionpool:https://public-asai-dl-models.s3.eu-central-1.amazonaws.com:443 \"GET /DeepPhonemizer/en_us_cmudict_forward.pt HTTP/1.1\" 200 66725366\n",
            "/usr/local/lib/python3.11/dist-packages/dp/model/model.py:306: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(checkpoint_path, map_location=device)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(\n",
            "DEBUG:dp.phonemizer:Initializing phonemizer with model step 1120000\n",
            "WARNING:root:The word 'Sen_she_ent' was not found in the pronunciation dictionary! Using the DeepPhonemizer library to predict the phonemes.\n",
            "WARNING:root:Phones for 'Sen_she_ent': [S][EH][N][SH][IY][N][T]\n",
            "DEBUG:generate_samples:Loading /content/piper-sample-generator/models/en_US-libritts_r-medium.pt\n",
            "INFO:generate_samples:Successfully loaded the model\n",
            "DEBUG:generate_samples:Batch 1/142 complete\n",
            "DEBUG:generate_samples:Batch 2/142 complete\n",
            "DEBUG:generate_samples:Batch 3/142 complete\n",
            "DEBUG:generate_samples:Batch 4/142 complete\n",
            "DEBUG:generate_samples:Batch 5/142 complete\n",
            "DEBUG:generate_samples:Batch 6/142 complete\n",
            "DEBUG:generate_samples:Batch 7/142 complete\n",
            "DEBUG:generate_samples:Batch 8/142 complete\n",
            "DEBUG:generate_samples:Batch 9/142 complete\n",
            "DEBUG:generate_samples:Batch 10/142 complete\n",
            "DEBUG:generate_samples:Batch 11/142 complete\n",
            "DEBUG:generate_samples:Batch 12/142 complete\n",
            "DEBUG:generate_samples:Batch 13/142 complete\n",
            "DEBUG:generate_samples:Batch 14/142 complete\n",
            "DEBUG:generate_samples:Batch 15/142 complete\n",
            "DEBUG:generate_samples:Batch 16/142 complete\n",
            "DEBUG:generate_samples:Batch 17/142 complete\n",
            "DEBUG:generate_samples:Batch 18/142 complete\n",
            "DEBUG:generate_samples:Batch 19/142 complete\n",
            "DEBUG:generate_samples:Batch 20/142 complete\n",
            "DEBUG:generate_samples:Batch 21/142 complete\n",
            "DEBUG:generate_samples:Batch 22/142 complete\n",
            "DEBUG:generate_samples:Batch 23/142 complete\n",
            "DEBUG:generate_samples:Batch 24/142 complete\n",
            "DEBUG:generate_samples:Batch 25/142 complete\n",
            "DEBUG:generate_samples:Batch 26/142 complete\n",
            "DEBUG:generate_samples:Batch 27/142 complete\n",
            "DEBUG:generate_samples:Batch 28/142 complete\n",
            "DEBUG:generate_samples:Batch 29/142 complete\n",
            "DEBUG:generate_samples:Batch 30/142 complete\n",
            "DEBUG:generate_samples:Batch 31/142 complete\n",
            "DEBUG:generate_samples:Batch 32/142 complete\n",
            "DEBUG:generate_samples:Batch 33/142 complete\n",
            "DEBUG:generate_samples:Batch 34/142 complete\n",
            "DEBUG:generate_samples:Batch 35/142 complete\n",
            "DEBUG:generate_samples:Batch 36/142 complete\n",
            "DEBUG:generate_samples:Batch 37/142 complete\n",
            "DEBUG:generate_samples:Batch 38/142 complete\n",
            "DEBUG:generate_samples:Batch 39/142 complete\n",
            "DEBUG:generate_samples:Batch 40/142 complete\n",
            "DEBUG:generate_samples:Batch 41/142 complete\n",
            "DEBUG:generate_samples:Batch 42/142 complete\n",
            "DEBUG:generate_samples:Batch 43/142 complete\n",
            "DEBUG:generate_samples:Batch 44/142 complete\n",
            "DEBUG:generate_samples:Batch 45/142 complete\n",
            "DEBUG:generate_samples:Batch 46/142 complete\n",
            "DEBUG:generate_samples:Batch 47/142 complete\n",
            "DEBUG:generate_samples:Batch 48/142 complete\n",
            "DEBUG:generate_samples:Batch 49/142 complete\n",
            "DEBUG:generate_samples:Batch 50/142 complete\n",
            "DEBUG:generate_samples:Batch 51/142 complete\n",
            "DEBUG:generate_samples:Batch 52/142 complete\n",
            "DEBUG:generate_samples:Batch 53/142 complete\n",
            "DEBUG:generate_samples:Batch 54/142 complete\n",
            "DEBUG:generate_samples:Batch 55/142 complete\n",
            "DEBUG:generate_samples:Batch 56/142 complete\n",
            "DEBUG:generate_samples:Batch 57/142 complete\n",
            "DEBUG:generate_samples:Batch 58/142 complete\n",
            "DEBUG:generate_samples:Batch 59/142 complete\n",
            "DEBUG:generate_samples:Batch 60/142 complete\n",
            "DEBUG:generate_samples:Batch 61/142 complete\n",
            "DEBUG:generate_samples:Batch 62/142 complete\n",
            "DEBUG:generate_samples:Batch 63/142 complete\n",
            "DEBUG:generate_samples:Batch 64/142 complete\n",
            "DEBUG:generate_samples:Batch 65/142 complete\n",
            "DEBUG:generate_samples:Batch 66/142 complete\n",
            "DEBUG:generate_samples:Batch 67/142 complete\n",
            "DEBUG:generate_samples:Batch 68/142 complete\n",
            "DEBUG:generate_samples:Batch 69/142 complete\n",
            "DEBUG:generate_samples:Batch 70/142 complete\n",
            "DEBUG:generate_samples:Batch 71/142 complete\n",
            "DEBUG:generate_samples:Batch 72/142 complete\n",
            "DEBUG:generate_samples:Batch 73/142 complete\n",
            "DEBUG:generate_samples:Batch 74/142 complete\n",
            "DEBUG:generate_samples:Batch 75/142 complete\n",
            "DEBUG:generate_samples:Batch 76/142 complete\n",
            "DEBUG:generate_samples:Batch 77/142 complete\n",
            "DEBUG:generate_samples:Batch 78/142 complete\n",
            "DEBUG:generate_samples:Batch 79/142 complete\n",
            "DEBUG:generate_samples:Batch 80/142 complete\n",
            "DEBUG:generate_samples:Batch 81/142 complete\n",
            "DEBUG:generate_samples:Batch 82/142 complete\n",
            "DEBUG:generate_samples:Batch 83/142 complete\n",
            "DEBUG:generate_samples:Batch 84/142 complete\n",
            "DEBUG:generate_samples:Batch 85/142 complete\n",
            "DEBUG:generate_samples:Batch 86/142 complete\n",
            "DEBUG:generate_samples:Batch 87/142 complete\n",
            "DEBUG:generate_samples:Batch 88/142 complete\n",
            "DEBUG:generate_samples:Batch 89/142 complete\n",
            "DEBUG:generate_samples:Batch 90/142 complete\n",
            "DEBUG:generate_samples:Batch 91/142 complete\n",
            "DEBUG:generate_samples:Batch 92/142 complete\n",
            "DEBUG:generate_samples:Batch 93/142 complete\n",
            "DEBUG:generate_samples:Batch 94/142 complete\n",
            "DEBUG:generate_samples:Batch 95/142 complete\n",
            "DEBUG:generate_samples:Batch 96/142 complete\n",
            "DEBUG:generate_samples:Batch 97/142 complete\n",
            "DEBUG:generate_samples:Batch 98/142 complete\n",
            "DEBUG:generate_samples:Batch 99/142 complete\n",
            "DEBUG:generate_samples:Batch 100/142 complete\n",
            "DEBUG:generate_samples:Batch 101/142 complete\n",
            "DEBUG:generate_samples:Batch 102/142 complete\n",
            "DEBUG:generate_samples:Batch 103/142 complete\n",
            "DEBUG:generate_samples:Batch 104/142 complete\n",
            "DEBUG:generate_samples:Batch 105/142 complete\n",
            "DEBUG:generate_samples:Batch 106/142 complete\n",
            "DEBUG:generate_samples:Batch 107/142 complete\n",
            "DEBUG:generate_samples:Batch 108/142 complete\n",
            "DEBUG:generate_samples:Batch 109/142 complete\n",
            "DEBUG:generate_samples:Batch 110/142 complete\n",
            "DEBUG:generate_samples:Batch 111/142 complete\n",
            "DEBUG:generate_samples:Batch 112/142 complete\n",
            "DEBUG:generate_samples:Batch 113/142 complete\n",
            "DEBUG:generate_samples:Batch 114/142 complete\n",
            "DEBUG:generate_samples:Batch 115/142 complete\n",
            "DEBUG:generate_samples:Batch 116/142 complete\n",
            "DEBUG:generate_samples:Batch 117/142 complete\n",
            "DEBUG:generate_samples:Batch 118/142 complete\n",
            "DEBUG:generate_samples:Batch 119/142 complete\n",
            "DEBUG:generate_samples:Batch 120/142 complete\n",
            "DEBUG:generate_samples:Batch 121/142 complete\n",
            "DEBUG:generate_samples:Batch 122/142 complete\n",
            "DEBUG:generate_samples:Batch 123/142 complete\n",
            "DEBUG:generate_samples:Batch 124/142 complete\n",
            "DEBUG:generate_samples:Batch 125/142 complete\n",
            "DEBUG:generate_samples:Batch 126/142 complete\n",
            "DEBUG:generate_samples:Batch 127/142 complete\n",
            "DEBUG:generate_samples:Batch 128/142 complete\n",
            "DEBUG:generate_samples:Batch 129/142 complete\n",
            "DEBUG:generate_samples:Batch 130/142 complete\n",
            "DEBUG:generate_samples:Batch 131/142 complete\n",
            "DEBUG:generate_samples:Batch 132/142 complete\n",
            "DEBUG:generate_samples:Batch 133/142 complete\n",
            "DEBUG:generate_samples:Batch 134/142 complete\n",
            "DEBUG:generate_samples:Batch 135/142 complete\n",
            "DEBUG:generate_samples:Batch 136/142 complete\n",
            "DEBUG:generate_samples:Batch 137/142 complete\n",
            "DEBUG:generate_samples:Batch 138/142 complete\n",
            "DEBUG:generate_samples:Batch 139/142 complete\n",
            "DEBUG:generate_samples:Batch 140/142 complete\n",
            "DEBUG:generate_samples:Batch 141/142 complete\n",
            "DEBUG:generate_samples:Batch 142/142 complete\n",
            "DEBUG:generate_samples:Batch 143/142 complete\n",
            "INFO:generate_samples:Done\n",
            "INFO:root:##################################################\n",
            "Generating negative clips for testing\n",
            "##################################################\n",
            "DEBUG:dp.phonemizer:Initializing phonemizer with model step 1120000\n",
            "WARNING:root:The word 'Sen_she_ent' was not found in the pronunciation dictionary! Using the DeepPhonemizer library to predict the phonemes.\n",
            "WARNING:root:Phones for 'Sen_she_ent': [S][EH][N][SH][IY][N][T]\n",
            "DEBUG:generate_samples:Loading /content/piper-sample-generator/models/en_US-libritts_r-medium.pt\n",
            "INFO:generate_samples:Successfully loaded the model\n",
            "DEBUG:generate_samples:Batch 1/71 complete\n",
            "DEBUG:generate_samples:Batch 2/71 complete\n",
            "DEBUG:generate_samples:Batch 3/71 complete\n",
            "DEBUG:generate_samples:Batch 4/71 complete\n",
            "DEBUG:generate_samples:Batch 5/71 complete\n",
            "DEBUG:generate_samples:Batch 6/71 complete\n",
            "DEBUG:generate_samples:Batch 7/71 complete\n",
            "DEBUG:generate_samples:Batch 8/71 complete\n",
            "DEBUG:generate_samples:Batch 9/71 complete\n",
            "DEBUG:generate_samples:Batch 10/71 complete\n",
            "DEBUG:generate_samples:Batch 11/71 complete\n",
            "DEBUG:generate_samples:Batch 12/71 complete\n",
            "DEBUG:generate_samples:Batch 13/71 complete\n",
            "DEBUG:generate_samples:Batch 14/71 complete\n",
            "DEBUG:generate_samples:Batch 15/71 complete\n",
            "DEBUG:generate_samples:Batch 16/71 complete\n",
            "DEBUG:generate_samples:Batch 17/71 complete\n",
            "DEBUG:generate_samples:Batch 18/71 complete\n",
            "DEBUG:generate_samples:Batch 19/71 complete\n",
            "DEBUG:generate_samples:Batch 20/71 complete\n",
            "DEBUG:generate_samples:Batch 21/71 complete\n",
            "DEBUG:generate_samples:Batch 22/71 complete\n",
            "DEBUG:generate_samples:Batch 23/71 complete\n",
            "DEBUG:generate_samples:Batch 24/71 complete\n",
            "DEBUG:generate_samples:Batch 25/71 complete\n",
            "DEBUG:generate_samples:Batch 26/71 complete\n",
            "DEBUG:generate_samples:Batch 27/71 complete\n",
            "DEBUG:generate_samples:Batch 28/71 complete\n",
            "DEBUG:generate_samples:Batch 29/71 complete\n",
            "DEBUG:generate_samples:Batch 30/71 complete\n",
            "DEBUG:generate_samples:Batch 31/71 complete\n",
            "DEBUG:generate_samples:Batch 32/71 complete\n",
            "DEBUG:generate_samples:Batch 33/71 complete\n",
            "DEBUG:generate_samples:Batch 34/71 complete\n",
            "DEBUG:generate_samples:Batch 35/71 complete\n",
            "DEBUG:generate_samples:Batch 36/71 complete\n",
            "DEBUG:generate_samples:Batch 37/71 complete\n",
            "DEBUG:generate_samples:Batch 38/71 complete\n",
            "DEBUG:generate_samples:Batch 39/71 complete\n",
            "DEBUG:generate_samples:Batch 40/71 complete\n",
            "DEBUG:generate_samples:Batch 41/71 complete\n",
            "DEBUG:generate_samples:Batch 42/71 complete\n",
            "DEBUG:generate_samples:Batch 43/71 complete\n",
            "DEBUG:generate_samples:Batch 44/71 complete\n",
            "DEBUG:generate_samples:Batch 45/71 complete\n",
            "DEBUG:generate_samples:Batch 46/71 complete\n",
            "DEBUG:generate_samples:Batch 47/71 complete\n",
            "DEBUG:generate_samples:Batch 48/71 complete\n",
            "DEBUG:generate_samples:Batch 49/71 complete\n",
            "DEBUG:generate_samples:Batch 50/71 complete\n",
            "DEBUG:generate_samples:Batch 51/71 complete\n",
            "DEBUG:generate_samples:Batch 52/71 complete\n",
            "DEBUG:generate_samples:Batch 53/71 complete\n",
            "DEBUG:generate_samples:Batch 54/71 complete\n",
            "DEBUG:generate_samples:Batch 55/71 complete\n",
            "DEBUG:generate_samples:Batch 56/71 complete\n",
            "DEBUG:generate_samples:Batch 57/71 complete\n",
            "DEBUG:generate_samples:Batch 58/71 complete\n",
            "DEBUG:generate_samples:Batch 59/71 complete\n",
            "DEBUG:generate_samples:Batch 60/71 complete\n",
            "DEBUG:generate_samples:Batch 61/71 complete\n",
            "DEBUG:generate_samples:Batch 62/71 complete\n",
            "DEBUG:generate_samples:Batch 63/71 complete\n",
            "DEBUG:generate_samples:Batch 64/71 complete\n",
            "DEBUG:generate_samples:Batch 65/71 complete\n",
            "DEBUG:generate_samples:Batch 66/71 complete\n",
            "DEBUG:generate_samples:Batch 67/71 complete\n",
            "DEBUG:generate_samples:Batch 68/71 complete\n",
            "DEBUG:generate_samples:Batch 69/71 complete\n",
            "DEBUG:generate_samples:Batch 70/71 complete\n",
            "DEBUG:generate_samples:Batch 71/71 complete\n",
            "DEBUG:generate_samples:Batch 72/71 complete\n",
            "INFO:generate_samples:Done\n",
            "/usr/local/lib/python3.11/dist-packages/torch_audiomentations/utils/io.py:27: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.\n",
            "  torchaudio.set_audio_backend(\"soundfile\")\n",
            "INFO:root:##################################################\n",
            "Computing openwakeword features for generated samples\n",
            "##################################################\n",
            "/usr/local/lib/python3.11/dist-packages/torch_audiomentations/core/transforms_interface.py:77: FutureWarning: Transforms now expect an `output_type` argument that currently defaults to 'tensor', will default to 'dict' in v0.12, and will be removed in v0.13. Make sure to update your code to something like:\n",
            "  >>> augment = PitchShift(..., output_type='dict')\n",
            "  >>> augmented_samples = augment(samples).samples\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch_audiomentations/core/transforms_interface.py:77: FutureWarning: Transforms now expect an `output_type` argument that currently defaults to 'tensor', will default to 'dict' in v0.12, and will be removed in v0.13. Make sure to update your code to something like:\n",
            "  >>> augment = BandStopFilter(..., output_type='dict')\n",
            "  >>> augmented_samples = augment(samples).samples\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch_audiomentations/core/transforms_interface.py:77: FutureWarning: Transforms now expect an `output_type` argument that currently defaults to 'tensor', will default to 'dict' in v0.12, and will be removed in v0.13. Make sure to update your code to something like:\n",
            "  >>> augment = AddColoredNoise(..., output_type='dict')\n",
            "  >>> augmented_samples = augment(samples).samples\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch_audiomentations/core/transforms_interface.py:77: FutureWarning: Transforms now expect an `output_type` argument that currently defaults to 'tensor', will default to 'dict' in v0.12, and will be removed in v0.13. Make sure to update your code to something like:\n",
            "  >>> augment = AddBackgroundNoise(..., output_type='dict')\n",
            "  >>> augmented_samples = augment(samples).samples\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch_audiomentations/core/transforms_interface.py:77: FutureWarning: Transforms now expect an `output_type` argument that currently defaults to 'tensor', will default to 'dict' in v0.12, and will be removed in v0.13. Make sure to update your code to something like:\n",
            "  >>> augment = Gain(..., output_type='dict')\n",
            "  >>> augmented_samples = augment(samples).samples\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch_audiomentations/core/composition.py:42: FutureWarning: Transforms now expect an `output_type` argument that currently defaults to 'tensor', will default to 'dict' in v0.12, and will be removed in v0.13. Make sure to update your code to something like:\n",
            "  >>> augment = Compose(..., output_type='dict')\n",
            "  >>> augmented_samples = augment(samples).samples\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/audiomentations/core/transforms_interface.py:61: UserWarning: Warning: input samples dtype is np.float64. Converting to np.float32\n",
            "  warnings.warn(\n",
            "Computing features: 100% 62/62 [01:36<00:00,  1.56s/it]\n",
            "Trimming empty rows: 1it [00:00, 32.62it/s]\n",
            "Computing features: 100% 62/62 [01:22<00:00,  1.34s/it]\n",
            "Trimming empty rows: 1it [00:00, 35.84it/s]\n",
            "Computing features: 100% 31/31 [00:43<00:00,  1.39s/it]\n",
            "Trimming empty rows: 1it [00:00, 54.96it/s]\n",
            "Computing features: 100% 31/31 [00:52<00:00,  1.68s/it]\n",
            "Trimming empty rows: 1it [00:00, 59.80it/s]\n",
            "/usr/local/lib/python3.11/dist-packages/torch_audiomentations/utils/io.py:27: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.\n",
            "  torchaudio.set_audio_backend(\"soundfile\")\n",
            "INFO:root:##################################################\n",
            "Starting training sequence 1...\n",
            "##################################################\n",
            "Training: 100% 9999/10000 [08:27<00:00, 19.71it/s]\n",
            "INFO:root:##################################################\n",
            "Starting training sequence 2...\n",
            "##################################################\n",
            "INFO:root:Increasing weight on negative examples to reduce false positives...\n",
            "Training: 100% 999/1000.0 [03:47<00:00,  4.38it/s]\n",
            "INFO:root:##################################################\n",
            "Starting training sequence 3...\n",
            "##################################################\n",
            "INFO:root:Increasing weight on negative examples to reduce false positives...\n",
            "Training: 100% 999/1000.0 [04:13<00:00,  3.94it/s]\n",
            "INFO:root:Merging checkpoints above the 90th percentile into single model...\n",
            "INFO:root:\n",
            "################\n",
            "Final Model Accuracy: 0.7229999899864197\n",
            "Final Model Recall: 0.4580000042915344\n",
            "Final Model False Positives per Hour: 0.8849557638168335\n",
            "################\n",
            "\n",
            "INFO:root:####\n",
            "Saving ONNX mode as '/content/my_custom_model/Hey_Sen_she_ent.onnx'\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/openwakeword/openwakeword/train.py\", line 901, in <module>\n",
            "    convert_onnx_to_tflite(os.path.join(config[\"output_dir\"], config[\"model_name\"] + \".onnx\"),\n",
            "  File \"/content/openwakeword/openwakeword/train.py\", line 578, in convert_onnx_to_tflite\n",
            "    from onnx_tf.backend import prepare\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/onnx_tf/__init__.py\", line 1, in <module>\n",
            "    from . import backend\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/onnx_tf/backend.py\", line 21, in <module>\n",
            "    import tensorflow as tf\n",
            "ModuleNotFoundError: No module named 'tensorflow'\n"
          ]
        },
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'tensorflow'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-c802ee0a7557>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m \u001b[0mconvert_onnx_to_tflite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"my_custom_model/{config['model_name']}.onnx\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"my_custom_model/{config['model_name']}.tflite\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;31m# Automatically download the trained model files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-c802ee0a7557>\u001b[0m in \u001b[0;36mconvert_onnx_to_tflite\u001b[0;34m(onnx_model_path, output_path)\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mtempfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0monnx_tf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprepare\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/onnx_tf/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m__version__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/onnx_tf/backend.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0monnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunner\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBackendIsNotSupposedToImplementIt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0monnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhelper\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmake_opsetid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# @title  { display-mode: \"form\" }\n",
        "# @markdown # 3. Train the Model\n",
        "# @markdown Now that you have verified your target wake word and downloaded the data,\n",
        "# @markdown the last step is to adjust the training paramaters (or keep\n",
        "# @markdown the defaults below) and start the training!\n",
        "\n",
        "# @markdown Each paramater controls a different aspect of training:\n",
        "# @markdown - `number_of_examples` controls how many examples of your wakeword\n",
        "# @markdown are generated. The default (1,000) usually produces a good model,\n",
        "# @markdown but between 30,000 and 50,000 is often the best.\n",
        "\n",
        "# @markdown - `number_of_training_steps` controls how long to train the model.\n",
        "# @markdown Similar to the number of examples, the default (10,000) usually works well\n",
        "# @markdown but training longer usually helps.\n",
        "\n",
        "# @markdown - `false_activation_penalty` controls how strongly false activations\n",
        "# @markdown are penalized during the training process. Higher values can make the model\n",
        "# @markdown much less likely to activate when it shouldn't, but may also cause it\n",
        "# @markdown to not activate when the wake word isn't spoken clearly and there is\n",
        "# @markdown background noise.\n",
        "\n",
        "# @markdown With the default values shown below,\n",
        "# @markdown this takes about 30 - 60 minutes total on the normal CPU Colab runtime.\n",
        "# @markdown If you want to train on more examples or train for longer,\n",
        "# @markdown try changing the runtime type to a GPU to significantly speedup\n",
        "# @markdown the example generating and model training.\n",
        "\n",
        "# @markdown When the model finishes training, you can navigate to the `my_custom_model` folder\n",
        "# @markdown in the file browser on the left (click on the folder icon), and download\n",
        "# @markdown the [your target wake word].onnx or  <your target wake word>.tflite files.\n",
        "# @markdown You can then use these as you would any other openWakeWord model!\n",
        "\n",
        "# Load default YAML config file for training\n",
        "import yaml\n",
        "config = yaml.load(open(\"openwakeword/examples/custom_model.yml\", 'r').read(), yaml.Loader)\n",
        "\n",
        "# Modify values in the config and save a new version\n",
        "number_of_examples = 1000 # @param {type:\"slider\", min:100, max:50000, step:50}\n",
        "number_of_training_steps = 10000  # @param {type:\"slider\", min:0, max:50000, step:100}\n",
        "false_activation_penalty = 1500  # @param {type:\"slider\", min:100, max:5000, step:50}\n",
        "config[\"target_phrase\"] = [target_word]\n",
        "config[\"model_name\"] = config[\"target_phrase\"][0].replace(\" \", \"_\")\n",
        "config[\"n_samples\"] = number_of_examples\n",
        "config[\"n_samples_val\"] = max(500, number_of_examples//10)\n",
        "config[\"steps\"] = number_of_training_steps\n",
        "config[\"target_accuracy\"] = 0.5\n",
        "config[\"target_recall\"] = 0.25\n",
        "config[\"output_dir\"] = \"./my_custom_model\"\n",
        "config[\"max_negative_weight\"] = false_activation_penalty\n",
        "\n",
        "config[\"background_paths\"] = ['./audioset_16k', './fma']  # multiple background datasets are supported\n",
        "config[\"false_positive_validation_data_path\"] = \"validation_set_features.npy\"\n",
        "config[\"feature_data_files\"] = {\"ACAV100M_sample\": \"openwakeword_features_ACAV100M_2000_hrs_16bit.npy\"}\n",
        "\n",
        "with open('my_model.yaml', 'w') as file:\n",
        "    documents = yaml.dump(config, file)\n",
        "\n",
        "# Generate clips\n",
        "!{sys.executable} openwakeword/openwakeword/train.py --training_config my_model.yaml --generate_clips\n",
        "\n",
        "# Step 2: Augment the generated clips\n",
        "\n",
        "!{sys.executable} openwakeword/openwakeword/train.py --training_config my_model.yaml --augment_clips\n",
        "\n",
        "# Step 3: Train model\n",
        "\n",
        "!{sys.executable} openwakeword/openwakeword/train.py --training_config my_model.yaml --train_model\n",
        "\n",
        "# Manually save to tflite as this doesn't work right in colab\n",
        "def convert_onnx_to_tflite(onnx_model_path, output_path):\n",
        "    \"\"\"Converts an ONNX version of an openwakeword model to the Tensorflow tflite format.\"\"\"\n",
        "    # imports\n",
        "    import onnx\n",
        "    import logging\n",
        "    import tempfile\n",
        "    from onnx_tf.backend import prepare\n",
        "    import tensorflow as tf\n",
        "\n",
        "    # Convert to tflite from onnx model\n",
        "    onnx_model = onnx.load(onnx_model_path)\n",
        "    tf_rep = prepare(onnx_model, device=\"CPU\")\n",
        "    with tempfile.TemporaryDirectory() as tmp_dir:\n",
        "        tf_rep.export_graph(os.path.join(tmp_dir, \"tf_model\"))\n",
        "        converter = tf.lite.TFLiteConverter.from_saved_model(os.path.join(tmp_dir, \"tf_model\"))\n",
        "        tflite_model = converter.convert()\n",
        "\n",
        "        logging.info(f\"####\\nSaving tflite mode to '{output_path}'\")\n",
        "        with open(output_path, 'wb') as f:\n",
        "            f.write(tflite_model)\n",
        "\n",
        "    return None\n",
        "\n",
        "convert_onnx_to_tflite(f\"my_custom_model/{config['model_name']}.onnx\", f\"my_custom_model/{config['model_name']}.tflite\")\n",
        "\n",
        "# Automatically download the trained model files\n",
        "from google.colab import files\n",
        "\n",
        "files.download(f\"my_custom_model/{config['model_name']}.onnx\")\n",
        "files.download(f\"my_custom_model/{config['model_name']}.tflite\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0106fa30d61a43d1baa5e23b2c2da35a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28b901e22b93410b8e7a2358d1cd8005": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f4b2e3ca0c5b46dd9e7c704e543a5f45",
              "IPY_MODEL_46caee6dc8954c55820c35d059f144b6",
              "IPY_MODEL_798050445e6e4b688753137c835881c5"
            ],
            "layout": "IPY_MODEL_864c43b961fe411d824fb32eb25a37b3"
          }
        },
        "30cd5019f5cc4affb551ef4d859ac13e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3b0e8a6138f7458e846fb1a2b5c39eac": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "46348ce816ce40979a14d7a1f6e760da": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_89b2f53e578f40438cfd2cb5773bd4dd",
            "placeholder": "​",
            "style": "IPY_MODEL_c23258cebd674fdcb1bbf13dfb1b9ed2",
            "value": " 46.3k/46.3k [00:00&lt;00:00, 2.83MB/s]"
          }
        },
        "46caee6dc8954c55820c35d059f144b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0106fa30d61a43d1baa5e23b2c2da35a",
            "max": 25,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c0514b32c9304b0fab7f89fdaa5d13b6",
            "value": 25
          }
        },
        "53c4e8d743204d36b80a267957f20e2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_69fadcb11a9840cba289e79c4dc449e2",
            "placeholder": "​",
            "style": "IPY_MODEL_3b0e8a6138f7458e846fb1a2b5c39eac",
            "value": "Downloading builder script: 100%"
          }
        },
        "69fadcb11a9840cba289e79c4dc449e2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b26acf8628f43749cbff0f41298a860": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "798050445e6e4b688753137c835881c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d41b3c7af4e5466d8da393d637a058ee",
            "placeholder": "​",
            "style": "IPY_MODEL_8281106d178d48a7ad614cab6a6fe537",
            "value": " 25.0/25.0 [00:00&lt;00:00, 1.52kB/s]"
          }
        },
        "8281106d178d48a7ad614cab6a6fe537": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "864c43b961fe411d824fb32eb25a37b3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "89b2f53e578f40438cfd2cb5773bd4dd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97ab69917e9f40b09dd2fa703a3765f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9e7b5702f4f34efa91ed2b2b3fabd62b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_53c4e8d743204d36b80a267957f20e2b",
              "IPY_MODEL_cffebad06704453a827883d23af371e2",
              "IPY_MODEL_46348ce816ce40979a14d7a1f6e760da"
            ],
            "layout": "IPY_MODEL_6b26acf8628f43749cbff0f41298a860"
          }
        },
        "9f96400f76ae44219d1c3f5c9104e6e6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a68023d84ab34248a312b2fa5a2892fd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c0514b32c9304b0fab7f89fdaa5d13b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c23258cebd674fdcb1bbf13dfb1b9ed2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cffebad06704453a827883d23af371e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f96400f76ae44219d1c3f5c9104e6e6",
            "max": 46287,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_30cd5019f5cc4affb551ef4d859ac13e",
            "value": 46287
          }
        },
        "d41b3c7af4e5466d8da393d637a058ee": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4b2e3ca0c5b46dd9e7c704e543a5f45": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a68023d84ab34248a312b2fa5a2892fd",
            "placeholder": "​",
            "style": "IPY_MODEL_97ab69917e9f40b09dd2fa703a3765f8",
            "value": "Downloading readme: 100%"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
